import Image from "next/image";
import PageWrapper from "../components/pagewrapper";

export default function IntroductionPage() {
    return (
        <PageWrapper>
            <div style={{ fontFamily: 'Arial, sans-serif', lineHeight: '1.6', margin: '20px', padding: '20px' }}>
                <h1 style={{ textAlign: 'center' }}>Welcome to Metaculus</h1>

                <p>The purpose of this page is to give an intro to brand-new visitors to Metaculus who want to know more and could potentially turn into brand-new baby forecasters if they had just a bit more context about why they should care.</p>

                <h2>Why Forecasting Matters</h2>
                <p>Have you ever found yourself in a disagreement with someone, where you each expected the future to play out completely differently? Maybe you were discussing whether a new technology would be the next big thing, or if a recession was looming, or the outcome of a presidential election.</p>

                <p>These conversations often leave everyone frustrated, talking past one another, and they rarely reach a satisfying conclusion. Often they suffer from:</p>
                <ul>
                    <li><strong>Vague language:</strong> We might say something is “probably” or “likely.” But what does that mean, really?</li>
                    <li><strong>No accountability:</strong> No one is checking to see whether those bold claims—made in the heat of the argument—actually came true!</li>
                    <li><strong>Unclear expectations:</strong> What outcomes are we even talking about? Do we expect something to happen in the next two weeks—or the next two years?</li>
                </ul>

                <h2>Enter Forecasting</h2>
                <p>Forecasting is the practice of making explicit predictions about the future. Instead of vague assertions, forecasters share:</p>
                <ul>
                    <li>Specific probabilities — like what your weatherperson uses to help you decide if you’re taking an umbrella with you when you leave the house.</li>
                    <li>Concrete dates</li>
                    <li>Measurable outcomes</li>
                </ul>

                <blockquote>“There’s a big risk of recession sometime soon.”</blockquote>
                <p>Okay, but what’s a “big risk”? When is “soon”? Do you think it probably won’t actually happen, but that there’s higher risk than usual? Do you think it’s basically guaranteed?</p>

                <p>A forecaster might instead say, “There’s a 60% chance the US enters a recession in the next 12 months.” Much clearer! We might agree or disagree with them, but now we know how likely they think it is and when they think it’ll happen. If ultimately they’re right, we know it. If they’re wrong, well, at least they were willing to say what they actually believed with clarity and accountability.</p>

             
                <p><b>That’s what Metaculus is all about: questions that matter to people, clearly defined, giving you the ability to make forecasts and follow up on whether they were accurate.</b></p>

                <p>And when you start regularly using Metaculus, it becomes more than a forecasting platform — it becomes a whole new way of thinking, one that generates more productive disagreements and conversations that are grounded in what will actually happen, and in which pieces of evidence point toward which future.</p>

                <h2>Wisdom of the Crowd</h2>
                <p>You might wonder, “If anyone can join Metaculus, why should I care what the ‘Community Prediction’ says about a topic? Why would I expect it to be right?” It’s a great question with two answers:</p>

                <ol>
                    <li><strong>Surprisingly Accurate:</strong> The wisdom of the crowd is surprisingly—even startlingly—accurate. Metaculus keeps a transparent record of all resolved questions, which can be sorted by topic. <a href="https://www.metaculus.com/questions/track-record/" target="_blank" rel="noopener noreferrer">You can explore it here.</a></li>
                    <li><strong>Probabilistic Forecasts:</strong> When there’s a forecast saying “40% chance of rain” — and then it doesn’t rain — it’s not quite right to call that individual forecast incorrect. Instead, you should expect something like: “When there’s a 40% chance of rain, that means four out of ten times, there should indeed be rain.”</li>
                </ol>

                <p>That’s what a calibration plot gets you. Here’s ours, measured over literally thousands of questions and millions of predictions by the Metaculus community:</p>

                <Image
                    src="https://metaculus-public.s3.us-west-2.amazonaws.com/Screenshot+2024-10-29+at+10.35.48%E2%80%AFPM.png"
                    alt="Calibration Plot"
                    width={800}
                    height={450}
                    priority
                />

                <p>Perfect calibration would look like a straight line. When you give something 10% likelihood, it should happen one out of ten times. 90% likely, it should happen nine out of ten times. (This isn’t the only way to measure forecast accuracy, but it’s one of the more intuitive ways. <a href="https://www.metaculus.com/questions/track-record/" target="_blank" rel="noopener noreferrer">You can find more on our Track Record page.</a>)</p>

                <h2>The Power of Aggregation</h2>
                <p>Here’s another example: When 3000+ people competed in this contest to predict what would happen in 2023, only three individuals outperformed the Metaculus aggregate. That puts the aggregate in the 99.5th percentile of performance! Now, this performance is a nice illustration of the power of the wisdom of the crowd — and we’re very proud of the Metaculus community’s performance — but, one should always be wary of cherry-picked forecasting results. <a href="https://www.metaculus.com/questions/track-record/" target="_blank" rel="noopener noreferrer">You can view the full Track Record page here.</a></p>

                <h2>The Science of Forecasting</h2>
                <p>So, the empirical record is one reason one might find Metaculus’s aggregate forecasts persuasive. Here’s the second:</p>

                <p>There’s a fascinating research literature on the effectiveness of the wisdom of the crowd and on forecasting as a skill one can develop — a skill that’s distinct from whatever specialized domain knowledge one might have. Research by University of Pennsylvania psychologists Philip Tetlock and Barbara Mellers found that the aggregated geopolitical predictions of top forecasters were more accurate than those of CIA analysts with access to classified information.</p>

                <p>Tetlock's groundbreaking research, much of it detailed in his book <em>Superforecasting</em>, shows that forecasting is a skill that can be developed with practice, feedback, and the right mindset. <b>Metaculus is the platform where anyone can hone this skill.</b></p>

                <p><b>Join Metaculus and help make the future clearer.</b></p>
            </div>
        </PageWrapper>
    );
}
